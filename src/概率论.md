# 概率论

## 1. 测度空间

**在测度论中继续学习**

## 2. 可测空间

设$\Omega$是试验$S$的样本空间，用$F$表示$\Omega$的某些子集构成的集合，如果$F$满足：

1. $\Omega\in{F}$

2. 如果$A\in{F}$，那么$\overline{A}\in{F}$

3. 如果$A_j\in{F}$，那么$\bigcup\limits_{j=1}^{\infty}A_j\in{F}$

那么称$F$是$\Omega$的$\sigma$域，称$(\Omega,F)$是可测空间

## 3. 概率空间

#### 3.1 概率空间的定义

设$(\Omega,F)$是可测空间，$P$是定义在$F$上的函数，如果$P$满足以下的条件：

1. 非负性：对$A\in{F}$，有$P(A)\geq{0}$

2. 完全性：$P(\Omega)=1$

3. 可列可加性：对于$F$中互不相容的事件$A_1$，$A_2$，$\dots$，$P(\bigcup\limits_{j=1}^{\infty}A_j)=\sum\limits_{j=1}^{\infty}{P(A_j)}$

则称$P$是$F$上的概率测度，简称概率，称$(\Omega,F,P)$是概率空间

#### 3.2 几乎处处

对于$A\in{\Omega}$，如果$P(A)=1$，就称$A$以概率1发生，或几乎处处发生，记作$a.s.$

## 4. 条件概率

#### 4.1 条件概率公式

$P(B|A)=\frac{P(AB)}{P(A)}$

#### 4.2 条件概率测度

设$(\Omega,F,P)$是概率空间，$A\in{F}$，$P(A)>0$。定义$P_A(B)=P(B|A)$，$B\in{F}$，则称$P_A$也是可测空间$(\Omega,F)$上的概率，称$P_A$是条件概率测度。

#### 4.3 贝叶斯公式

$P(A_i|B)=\frac{P(B|A_i)P(A_i)}{\sum\limits_{j=1}^{n}{P(B|A_j)P(A_j)}}$

#### 4.4 似然函数

统计学中，似然函数是一种关于统计模型参数的函数。给定输出$x$时，关于参数$θ$的似然函数$L(θ|x)$（在数值上）等于给定参数$θ$后变量$X$的概率：$L(θ|x)=P(X=x|θ)$。

#### 4.5 贝叶斯估计

$P(H|E)=\frac{P(E|H)P(H)}{P(E)}$

其中，$P(H)$是先验概率，在观测到数据之前假说$H$的概率。

$P(H|E)$是后验概率，是在给定证据$E$之后，假说$H$的概率。

$P(E|H)$是假定$H$成立时，观察到$E$的概率。这也是以证据$E$为参数的似然函数。

## 5. 随机变量

#### 5.1 随机变量

设$(\Omega,F)$是可测空间，如果$\Omega$上的函数$X(\omega)$满足对任何实数$x$，$\{\omega|X(\omega)\leq{x}\}\in{F}$，那么称$X(\omega)$是可测空间$(\Omega,F)$上的随机变量，简称随机变量

#### 5.2 Borel域和Borel集

用$C^n$表示$R^n$的全体子立方体，用$B^n$表示$C^n$中的立方体们经过交集、余集和可列并集的运算及其反复运算得到的集合的全体，则$B^n$是$\sigma$域，称为$n$维Borel域，其中的元素称为$n$维Borel集。

## 6. 分布、概率密度、期望、方差与条件数学期望

#### 6.1 定理6.1 独立变量的联合概率密度 (见《概率论》p107)

设随机变量$X_i$有概率密度$f_i(x_i)$，则$X_1,X_2,\cdots{X_n}$相互独立的充分必要条件是随机变量(X_1,X_2,\cdots{X_n})有联合密度

$f_1(x_1)f_2(x_2)\cdots{f_n(x_n)}$

#### 6.2 定理6.2 （见《概率论》p119）

设$(X_1,Y_1)$和$(X_2,Y_2)$有相同的联合分布和联合概率密度，$g(x,y)$和$h(x,y)$是二维实函数，定义

$$
\left \{
\begin{array}{l}

Z_1=g(X_1,Y_1) \\

W_1=h(X_1,Y_1)  \\

Z_2=g(X_2,Y_2) \\

W_2=h(X_2,Y_2)

\end{array}

\right.
$$

则$(Z_1,W_1)$和$(Z_2,W_2)$有相同的联合分布。

**证明：**
$$
\begin{align}
& \ P(Z_1\leq{z},W_1\leq{w})  \\
= & \ P(g(X_1,Y_1)\leq{z},h(X_1,Y_1)\leq{w}) \\
= & \ \int_{{R}^{2}}I_{\{g(x,y)\leq{z},h(x,y)\leq{w}\}}f(x,y)dxdy \\
= & \ P(g(X_2,Y_2)\leq{z}, \ h(X_2,Y_2)\leq{w}) \\
= & \ P(Z_2\leq{z},W_2\leq{w})
\end{align}
$$

#### 6.3 定理6.3 期望的性质 （见《概率论》p154）

设$E(|X_j|)\leq{\infin}$，${X_j}$相互独立，$（X_1,X_2,\cdots,X_n）$有联合概率密度，则$Z=X_1X_2\cdots{X_n}$的数学期望存在，且$E(Z)=E(X_1)E(X_2)\cdots{E(X_n)}$

**证明：**

根据Fubini定理

$$
\begin{align}
E(|Y|)= & \int_{R^n}|x_1x_2\cdots{x_n}|f(x_1,x_2,\cdots{x_n})dx_1dx_2\cdots{dx_n}  \\

= & \int_{-\infin}^{\infin}|x_1|f_1(x_1)dx_1\int_{-\infin}^{\infin}|x_2|f_2(x_2)dx_2\cdots{\int_{-\infin}^{\infin}|x_n|f_n(x_n)dx_n} \\

= & |E(X_1)||E(X_2)|\cdots{|E(X_n)|} < \infin

\end{align}
$$

因此，$E(Y)$是绝对可积的。

再次运用Fubini定理，

$$
\begin{align}
E(Y)= & \int_{R^n}x_1x_2\cdots{x_n}f(x_1,x_2,\cdots{x_n})dx_1dx_2\cdots{dx_n}  \\

= & \int_{-\infin}^{\infin}x_1f_1(x_1)dx_1\int_{-\infin}^{\infin}x_2f_2(x_2)dx_2\cdots{\int_{-\infin}^{\infin}x_nf_n(x_n)dx_n} \\

= & E(X_1)E(X_2)\cdots{E(X_n)}

\end{align}
$$

**注：Fubini定理**

**在数学分析中学习**

#### 6.4 定理6.4 方差的性质 （见《概率论》p165）

设$X_1,X_2,\cdots{X_n}$相互独立，那么$var(\sum\limits_{j=1}^{n}X_j)=\sum\limits_{j=1}^{n}var(X_j)$

由定理6.1可知，$E(XY)=E(X)E(Y)$，因此证明从略。

## 7. Markov不等式、切比雪夫不等式与内积不等式

#### 7.1 Markov 不等式

对随机变量$X$和$\varepsilon>0$，有$P(|X|>\epsilon)\leq{\frac{1}{\varepsilon^{\alpha}}E|X|^{\alpha}}$，$\alpha>0$

**证明比较简单，此处略。**

#### 7.2 切比雪夫不等式

对Markov不等式的$\alpha$取值$\alpha=2$，可得$P(|X|>\epsilon)\leq{\frac{1}{\varepsilon^{2}}var(X)}$

#### 7.3 随机变量线性相关的定义

如果随机变量$X_1，X_2,\cdots{X_n}$满足：存在不全为0的$a_1,a_2,\cdots,a_n$，使得$P(\sum\limits_{i=0}^n{a_iX_i=0})=1$，那么称$X_1，X_2,\cdots{X_n}$线性相关。

#### 7.4 内积不等式

设$EX^2<\infin$，$EY^2<\infin$，那么$|E(XY)|\leq(EX^2EY^2)^{\frac{1}{2}}$，其中等号成立的充分必要条件是$X$和$Y$线性相关。

**证明：**

考虑二次型：
$E(aX+bY)^2=a^2EX^2+2abEXY+b^2EY^2=(a,b)()(a,b)^T\geq{0}$

因此，（）是半正定的，因此$det\geq{0}$，原命题得证。

## 8. 协方差与相关系数

#### 8.1 协方差的定义

设$\mu_X=EX$和$\mu_Y=EY$都存在，那么$E[(X-\mu_X)(Y-\mu_Y)]$称作随机变量$X$和$Y$的协方差，记作$cov(X,Y)$或者$\sigma_{XY}$。

如果$cov(X,Y)=0$，那么称$X$和$Y$不相关。

#### 8.2 相关系数的定义

若$0<\sigma_X \sigma_Y<\infin$，那么称$\rho_{XY}=\frac{\sigma_{XY}}{\sigma_X \sigma_Y}$为$X$和$Y$的相关系数。

#### 8.3 相关系数的性质

1. $|\rho_{XY}|=1$的充分必要条件是$X$和$Y$线性相关。

2. 如果$X$和$Y$独立，则$X$和$Y$不相关。

**证明：**

性质1通过内积不等式证明显然，此处略。

性质2通过定理6.3证明显然，此处略。

#### 8.4 矩阵的退化

如果对给定的矩阵$A$，有矩阵$B$满足$AB=I$，那么称$A$是非退化的，称$B$是$A$的逆矩阵，否则称$A$是退化的。

对于方阵$A$，$A$退化的充分必要条件是$det(A)=0$。

#### 8.5 协方差矩阵的性质

设$\Sigma$是$X=(X_1,X_2,\cdots{X_n})$的协方差矩阵，则有如下性质：

1. $\Sigma$是半正定矩阵。

2. $\Sigma$退化的充分必要条件是$(X_1-EX_1),(X_2-EX_2)\cdots (X_n-EX_n)$线性相关。

**证明：**

1. 考虑$a\Sigma{a^T}$，$a\Sigma{a^T}=\sum\limits_{i=1}^{n}\sum\limits_{j=1}^{n}a_ia_j\sigma_{ij}=\sum\limits_{i=1}^{n}\sum\limits_{j=1}^{n}a_ia_jE[(X_i-\mu_i)(X_j-\mu_j)]$

   $=E[\sum\limits_{i=1}^{n}\sum\limits_{j=1}^{n}a_ia_j(X_i-\mu_i)(X_j-\mu_j)]=E[\sum\limits_{i=1}^na_i(X_i-\mu_i)]^2\geq{0}$

   命题得证。

1. 由性质1证明显然，此处略。

## 9. 母函数与特征函数

#### 9.1 母函数的定义

   $g(s)=E(s^X)=\sum\limits_{j=0}^{\infin}s^jP(X=j)$，其中，$X$是离散型非负随机变量，$s\in[-1,1]$，定义$0^0=1$。

#### 9.2 母函数的性质

   1. $P(X=k)=\frac{g^{(k)}(0)}{k!}$ ，随机变量$X$的分布和母函数是互相唯一确定的。
   2. $EX=g'(1)$。
   3. 如果$EX<\infin$，则$var(X)=g^{''}(1)+g^{'}(1)-(g^{'}(1))^2$。
   4. 如果$X_1,X_2,\cdots{X_n}$相互独立，$g_i(s)$是$X_i$的母函数，则$Y=X_1+X_2+\cdots{X_n}$有母函数$g_1(s)g_2(s)\cdots{g_n(s)}$。

**性质4的证明：**

   由于$X_1,X_2,\cdots{X_n}$相互独立，因此$s^{X_1},s^{X_2},\cdots,s^{X_n}$相互独立，因此$g_Y(s)=E(s^Y)=E(s^{X_1+X_2+\cdots{X_n}})=E(s^{X_1})E(s^{X_2})\cdots{E(s^{X_n})}=g_1(s)g_2(s)\cdots{g_n(s)}$。

#### 9.3 特征函数定义

   $\phi(t)=E(e^{itX})=Ecos(tX)+iEsin(tX)$，其中$X$是实值随机变量，$X,cos(tX),sin(tX)$的数学期望都存在。

#### 9.4 逆转公式

   设$\phi(t)$是X的特征函数，$F(x)$是$X$的分布函数，如果$F(X)$在$a,b$连续，则$F(b)-F(a)=\frac{1}{2\pi}\lim\limits_{T->\infin}\frac{e^{-ita}-e^{-ita}}{it}\phi(t)dt$

   随机变量$X$的特征函数和分布是互相唯一确定的。

#### 9.5 特征函数的性质

#### 9.6 特征函数的连续性定理

## 10. 两点分布

如果随机变量$X$只取值$0$和$1$，且满足：$P(X=1)=p$和$P(X=0)=1-p$，那么称$X$服从两点分布，记作$X\sim B(1,p) $。

## 11. 二项分布

#### 11.1 二项分布的定义

如果随机变量$X$有如下的概率分布：$P(X=k)=C_n^k p^k(1-p)^{n-k}$，则称$X$服从二项分布，记作$X\sim B(n,p)$。

#### 11.2 二项分布的方差

如果$X\sim B(n,p)$，那么$var(X)=np(1-p)$。

**证明：**

$var(X)=E[(X-\mu_X)^2]=EX^2-\mu_X^2=\sum\limits_{k=0}^nk^2C_n^kp^k(1-p)^{n-k}-\mu_X^2$

$=\sum\limits_{k=0}^nk(k-1)C_n^kp^k(1-p)^{n-k}+\sum\limits_{k=0}^nkC_n^kp^k(1-p)^{n-k}-\mu_X^2$

$=\frac{d}{dx^2}\sum\limits_{k=0}^{n}C_n^kx^{k+2}(1-p)^{n-k}|_{x=p}+\mu_X-\mu_X^2=p^2\frac{d}{dx^2}(x+1-p)^n)|_{x=p}+np-n^2p^2$

$=n(n-1)p^2+np-n^2p^2=np(1-p)$

## 12. 泊松分布

#### 12.1 泊松分布的定义

如果随机变量$X$有如下的概率分布：$P(X=k)=\frac{\lambda^k}{\lambda!}e^{-\lambda}$，那么称$X$服从参数为$\lambda$的泊松分布，记作$X\sim P(\lambda)$。

#### 12.2 泊松分布的实例

详见22.1。

#### 12.3 泊松分布的期望

如果$X\sim P(\lambda)$，那么$E(X)=\lambda$。

**证明：**

$E(X)=\sum\limits_{k=0}^{\infin}k\frac{\lambda^k}{k!}e^{-\lambda}=\lambda\sum\limits_{k=1}^{\infin}\frac{\lambda^{k-1}}{(k-1)!}e^{-\lambda}=\lambda$

#### 12.4 泊松分布的方差

如果$X\sim P(\lambda)$，那么$var(X)=\lambda$。

**证明：**

$var(X)=EX^2-E^2X=\sum\limits_{k=0}^{\infin}k^2\frac{\lambda^k}{k!}e^{-\lambda}-\lambda^2=\sum\limits_{k=0}^{\infin}k(k-1)\frac{\lambda^k}{k!}e^{-\lambda}+\sum\limits_{k=0}^{\infin}k\frac{\lambda^k}{k!}e^{-\lambda}-\lambda^2$

$=\lambda^2+\lambda-\lambda^2=\lambda$

## 13. 超几何分布

#### 13.1 超几何分布的定义

如果随机变量$X$有如下的概率分布：$P(X=k)=\frac{C_M^kC_{N-M}^{n-k}}{C_n^N}$，那么称$X$服从超几何分布，记作$X\sim H(n,M,H)$。

#### 13.2 超几何分布的实例

甲向一个目标进行射击，

## 14. 几何分布

#### 14.1 几何分布的定义

如果随机变量$X$有如下的概率分布：$P(X=k)=(1-p)^{k-1}p$，那么称$X$是服从参数是$p$的几何分布，记作$X \sim GE(p)$。

#### 14.2 离散型随机变量的无记忆性

称一个离散型随机变量$X$有无记忆性，如果对每一个$k\geq{1}$，都有$P(X=k+1|X>k)=P(X=1)$。

#### 14.3 几何分布和无记忆性的关系

取正整数值的随机变量$X$服从几何分布的充分必要条件是：$X$具有无记忆性。

**证明：**

首先证明必要性。

$P(X=k+1|X>k)=\frac{P(X=k+1)}{P(X>k)}=\frac{(1-p)^kp}{\sum\limits_{i=k+1}^{\infin}(1-p)^ip}=\frac{(1-p)^kp}{p\frac{(1-p)^k}{p}}=p=P(X=1)$

下面证明充分性。

设$P(X>k)=r_k$，那么$p=P(X=1)=\frac{P(X=k+1)}{P(X>k)}=\frac{P(X>k)-P(X>k+1)}{P(X>k)}=1-\frac{r_{k+1}}{r_k}$

因此$r_k=(1-p)^k$，即$P(X=k+1)=P(X>k)-P(X>k+1)=(1-p)^{k}-(1-p)^{k+1}=(1-p)^kp$

#### 14.4 几何分布的期望

如果$X\sim GE(p)$，那么$E(X)=\frac{1}{p}$。

**证明：**

记$q=1-p$，

$EX=\sum\limits_{i=1}^{\infin}iP(X=i)=\sum\limits_{i=1}^{\infin}iq^{i-1}(1-q)=(1-q)\frac{d}{dx}\frac{1}{1-x}|_{x=q}=\frac{1}{p}$

#### 14.5 几何分布的方差

如果$X\sim GE(p)$，那么$var(X)=\frac{q}{p^2}$。

**证明：**

$var(X)=EX^2-E^2X=\sum\limits_{i=1}^{\infin}i^2q^{i-1}(1-q)=\sum\limits_{i=1}^{\infin}i(i-1)q^{i-1}(1-q)+\sum\limits_{i=1}^{\infin}iq^{i-1}(1-q)-E^2X^2$

$=(1-q)q\frac{d^2}{d^2x}\frac{1}{1-x}|_{x=q}-(\frac{1}{p})^2=\frac{q}{p^2}$

## 15. 帕斯卡分布与负二项分布

如果随机变量$X$有如下的概率分布：$P(X=k)=C_{k-1}^{r-1}p^r(1-p)^{k-r}$，那么称$X$服从帕斯卡分布。

如果随机变量$Y$有如下的概率分布：$P(Y=k)=C_{k+r-1}^{r-1}p^r(1-p)^k$，那么称$Y$服从负二项分布。

值得注意的是，$X$和$Y$有如下关系：$X=Y+r$。

## 16. 均匀分布

如果随机变量$X$的概率密度函数满足：

$$
f(x)=\left\{

\begin{matrix}

\frac{1}{b-a} & x\in(a,b)\\

0 & x\notin(a,b)

\end{matrix}

\right.
$$

那么称$X$服从区间$(a,b)$上的均匀分布，记作$X \sim U(a,b)$。

## 17. 指数分布

#### 17.1 指数分布的定义

如果随机变量$X$的概率密度函数满足：

$$
f(x)=\left\{

\begin{matrix}

\lambda e^{-\lambda x}  & x\geq{0}  \\

0 & x<0

\end{matrix}

\right.
$$

那么称$X$服从参数为$\lambda$的指数分布，记作$X\sim \mathcal{E}(\lambda)$。

#### 17.2 指数分布的分布函数

$x<0$时，$F(x)=0$

$x\geq0$时，$F(x)=P(X<x)=\int_{0}^{x}\lambda e^{-\lambda y} dy=-e^{-\lambda y}|_{y=0}^{y=x}=1-e^{-\lambda y}$

#### 17.3 指数分布的实例

详见22.2。

#### 17.4 连续型随机变量的无记忆性

#### 17.5 指数分布与无记忆性的关系



#### 17.6 指数分布的期望

#### 17.7 指数分布的方差

## 18. $\Gamma$分布

## 19. 正态分布

## 20. 多元正态分布

## 21. 瑞利分布和柯西分布

## 22. $\alpha$粒子观测情况的实例

#### 22.1 $\alpha$粒子观测中的泊松分布

#### 22.2 $\alpha$粒子观测中的指数分布

#### 22.3 $\alpha$粒子观测中的$\Gamma$分布

## 23. 射击问题的实例

#### 23.1 射击问题中的几何分布

#### 23.2 射击问题中的帕斯卡分布

#### 23.3 射击问题中的负二项分布

## ？. 概率分布的熵

## ？. 依分布收敛、依概率收敛、弱收敛与几乎处处收敛 

## ？. 强大数率、弱大数率与中心极限定理

## ？. 次序统计量